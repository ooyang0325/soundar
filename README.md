<p align ="center"><img src="https://user-images.githubusercontent.com/52309935/201679137-983ad43a-ef6c-448d-9879-88063dc8ade5.png" width=15%></p>

<h1 align = "center">Map the World with Sound</h1>
<p align ="center"><img src="https://i.imgur.com/P1Ip1f9.jpg" width=75%></p>
<p align ="center">é®æ ¡ä¹‹å¯¶</p>

## åˆ†å·¥

**æ¥Šè© ç¿”**ï¼š

:heavy_check_mark: ç¾å·¥(PTTè£½ä½œç­‰)ã€dataset ç”Ÿæˆã€~~ç‘Ÿç‘Ÿ~~ã€å¸è€å©†ã€å™ç”·æ“”ç•¶ ğŸ¦¥ğŸ¦¥ğŸ¦¥

**è©¹æŒ¹è¾°**ï¼š

:heavy_check_mark: ç ”ç©¶æ–‡ç»ã€Model Training

**è‘‰å®¥è¾°**ï¼š

:heavy_check_mark: ç ”ç©¶æ–‡ç»ã€æ ¸é›»å» ç™¼é›»ã€:zap:
:u5272: 
:ok_hand: 
:banana:

## input data

* Mel Spectrogram (é »è­œåœ–)
* Raw data

## Output data

* åº§æ¨™
* $\frac{d(åº§æ¨™)}{dt}$

## Model

* CRNN
    * å°é »è­œåœ–åšå½±åƒè¾¨è­˜ (Failed) => ä¸åŒè·é›¢çš„é »è­œåœ–é•·å¤ªåƒäº† è¾¨è­˜ä¸å‡ºä¾†
* Transformer
    * ç›´æ¥æŠŠæ³¢å½¢ç ¸ in a nutshell
    * ç›®å‰çš„è³‡æ–™ä¸é©ç”¨(now we are using static single waveform file instead of a series of movement)


    sound generation using: 
    https://github.com/synthizer/synthizer

## HRTF ä»‹ç´¹

A head related transfer function (HRTF) describes the transformation of a specific source direction
relative to the head and filtering process associated with the diffraction of sound by
the pinna, head and torso.

## TO-DO list
- [x] pass the midterm(by any means) 
- [x] generate sound waveform files
- [x] create json file with waveform files' information
- [ ] build the enviroment on SYSTEX's server
- [ ] start training data
- [ ] marry my waifu **(!!important!!)** <br><br>
    > ooyang.waifu = {é›·å§†, å¤•å¤•å­, Aimyon, milet, å°æ¾èœå¥ˆ, é•·æ¾¤èŒ‰é‡Œå¥ˆ, æ©‹æœ¬ç’°å¥ˆ, æœæ—¥å¥ˆã¾ãŠ, æªœå±±æ²™è€¶}


[^_^]:
    possible handcrafted features extraction: Mel-Frequency Cepstrum, skewness, kurtosis, log energy, entropy, zcr
    

